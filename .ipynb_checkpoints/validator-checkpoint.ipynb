{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer,Dropout\n",
    "from keras.layers import LSTM\n",
    "from config.config import *\n",
    "from config.constants import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score,multilabel_confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current directory\n",
    "th_path = \"./TrainingSet/\"\n",
    "\n",
    "# list of file of the given path is assigned to the variable \n",
    "th_file_list = [th_path+each for each in list(os.walk(th_path))[0][-1] if \".csv\" in each]\n",
    "\n",
    "clus_path = './KMTrainingset/'\n",
    "\n",
    "clus_file_list = [clus_path+each for each in list(os.walk(clus_path))[0][-1] if \".csv\" in each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_th_model = load_model('manual_binary_clf.pkl')\n",
    "mul_th_model = load_model('manual_multi_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_clus_model = load_model('clus_binary_clf.pkl')\n",
    "mul_clus_model = load_model('clus_multi_clf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Testing threshold model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainingset + TH Binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {}\n",
    "for i in range(len(th_file_list)):\n",
    "\n",
    "    fault_type = re.sub(r'[0-9]+', '', th_file_list[i].split(\"/\")[-1].split(\".\")[0])\n",
    "    data = pd.read_csv(th_file_list[i])\n",
    "\n",
    "    original_labels = data['label']\n",
    "    #print(fault_type, set(original_labels))\n",
    "\n",
    "    original_labels = [1 if each!=0 else 0 for each in original_labels ]\n",
    "    data =data.drop('label',axis=1)\n",
    "    predicted_labels = np.argmax(bin_th_model.predict(data.values.reshape(-1,1,6)), axis=1)\n",
    "    \n",
    "    percentage = 100*[x-y for x,y in zip(original_labels,predicted_labels)].count(0)/data.shape[0]\n",
    "    \n",
    "    if fault_type not in list(matrix.keys()):\n",
    "        matrix[fault_type] = []\n",
    "        matrix[fault_type].append(percentage)\n",
    "    else:\n",
    "        matrix[fault_type].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABCG': 90.755, 'ABG': 95.77850000000001, 'BC': 97.17750000000001, 'CG': 98.543, 'BCG': 95.69, 'BG': 98.49599999999998, 'AG': 97.91500000000002, 'ABC': 89.962, 'ACG': 95.319, 'AC': 94.12750000000001, 'AB': 94.48400000000001}\n"
     ]
    }
   ],
   "source": [
    "for each in matrix.keys():\n",
    "    \n",
    "    matrix[each] = sum(matrix[each])/len(matrix[each])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.29522727272727"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matrix.values())/len(matrix.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMTrainingset + TH Binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {}\n",
    "for i in range(len(clus_file_list)):\n",
    "\n",
    "    fault_type = re.sub(r'[0-9]+', '', clus_file_list[i].split(\"/\")[-1].split(\".\")[0])\n",
    "    data = pd.read_csv(clus_file_list[i])\n",
    "\n",
    "    original_labels = data['label']\n",
    "    #print(fault_type, set(original_labels))\n",
    "\n",
    "    original_labels = [1 if each!=0 else 0 for each in original_labels ]\n",
    "    data =data.drop('label',axis=1)\n",
    "    predicted_labels = np.argmax(bin_th_model.predict(data.values.reshape(-1,1,6)), axis=1)\n",
    "    \n",
    "    percentage = 100*[x-y for x,y in zip(original_labels,predicted_labels)].count(0)/data.shape[0]\n",
    "    \n",
    "    if fault_type not in list(matrix.keys()):\n",
    "        matrix[fault_type] = []\n",
    "        matrix[fault_type].append(percentage)\n",
    "    else:\n",
    "        matrix[fault_type].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABCG': 74.454, 'ABG': 88.93350000000001, 'BC': 95.111, 'CG': 87.39799999999998, 'BCG': 80.32, 'BG': 96.1805, 'AG': 96.561, 'ABC': 82.6125, 'ACG': 88.69500000000001, 'AC': 93.18999999999998, 'AB': 93.444}\n"
     ]
    }
   ],
   "source": [
    "for each in matrix.keys():\n",
    "    \n",
    "    matrix[each] = sum(matrix[each])/len(matrix[each])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.80904545454544"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matrix.values())/len(matrix.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingset + Clus Binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {}\n",
    "for i in range(len(th_file_list)):\n",
    "\n",
    "    fault_type = re.sub(r'[0-9]+', '', th_file_list[i].split(\"/\")[-1].split(\".\")[0])\n",
    "    data = pd.read_csv(th_file_list[i])\n",
    "\n",
    "    original_labels = data['label']\n",
    "    #print(fault_type, set(original_labels))\n",
    "\n",
    "    original_labels = [1 if each!=0 else 0 for each in original_labels ]\n",
    "    data =data.drop('label',axis=1)\n",
    "    predicted_labels = np.argmax(bin_clus_model.predict(data.values.reshape(-1,1,6)), axis=1)\n",
    "    \n",
    "    percentage = 100*[x-y for x,y in zip(original_labels,predicted_labels)].count(0)/data.shape[0]\n",
    "    \n",
    "    if fault_type not in list(matrix.keys()):\n",
    "        matrix[fault_type] = []\n",
    "        matrix[fault_type].append(percentage)\n",
    "    else:\n",
    "        matrix[fault_type].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABCG': 74.254, 'ABG': 88.7625, 'BC': 94.04499999999999, 'CG': 91.95200000000001, 'BCG': 82.47149999999999, 'BG': 96.066, 'AG': 96.457, 'ABC': 67.553, 'ACG': 86.9515, 'AC': 88.53000000000002, 'AB': 90.01199999999999}\n"
     ]
    }
   ],
   "source": [
    "for each in matrix.keys():\n",
    "    \n",
    "    matrix[each] = sum(matrix[each])/len(matrix[each])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.00495454545454"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matrix.values())/len(matrix.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMTrainingset + Clus Binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = {}\n",
    "for i in range(len(clus_file_list)):\n",
    "\n",
    "    fault_type = re.sub(r'[0-9]+', '', clus_file_list[i].split(\"/\")[-1].split(\".\")[0])\n",
    "    data = pd.read_csv(clus_file_list[i])\n",
    "\n",
    "    original_labels = data['label']\n",
    "    #print(fault_type, set(original_labels))\n",
    "\n",
    "    original_labels = [1 if each!=0 else 0 for each in original_labels ]\n",
    "    data =data.drop('label',axis=1)\n",
    "    predicted_labels = np.argmax(bin_clus_model.predict(data.values.reshape(-1,1,6)), axis=1)\n",
    "    \n",
    "    percentage = 100*[x-y for x,y in zip(original_labels,predicted_labels)].count(0)/data.shape[0]\n",
    "    \n",
    "    if fault_type not in list(matrix.keys()):\n",
    "        matrix[fault_type] = []\n",
    "        matrix[fault_type].append(percentage)\n",
    "    else:\n",
    "        matrix[fault_type].append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABCG': 90.23700000000001, 'ABG': 99.956, 'BC': 99.94050000000001, 'CG': 91.246, 'BCG': 91.69800000000001, 'BG': 99.95400000000001, 'AG': 99.94450000000002, 'ABC': 99.819, 'ACG': 99.9375, 'AC': 99.92049999999999, 'AB': 99.911}\n"
     ]
    }
   ],
   "source": [
    "for each in matrix.keys():\n",
    "    \n",
    "    matrix[each] = sum(matrix[each])/len(matrix[each])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.50581818181819"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(matrix.values())/len(matrix.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_type = re.sub(r'[0-9]+', '', th_file_list[i].split(\"/\")[-1].split(\".\")[0])\n",
    "data = pd.read_csv(th_file_list[i])\n",
    "\n",
    "original_labels = data['label']\n",
    "#print(fault_type, set(original_labels))\n",
    "\n",
    "#original_labels = [1 if each!=0 else 0 for each in original_labels ]\n",
    "data =data.drop('label',axis=1)\n",
    "predicted_labels = np.argmax(bin_clus_model.predict(data.values.reshape(-1,1,6)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6455"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if each!=0 else 0 for each in original_labels ].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-170-0527d9e34b35>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-170-0527d9e34b35>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    list(predicted_labels).count(1)*100/\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list(predicted_labels).count(1)*100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
